Welcome to Streamlit-Ollama RAG Documentation
===========================================

.. toctree::
   :maxdepth: 2
   :caption: Contents:

   installation
   usage
   configuration
   api
   examples

Overview
--------
This project implements a Retrieval-Augmented Generation (RAG) system using Streamlit for the user interface and Ollama for model inference. The application allows users to interact with various language models while leveraging RAG for enhanced responses.

Key Features
-----------
* Streamlit-based user interface for easy interaction
* Integration with Ollama for model inference
* RAG implementation for improved response accuracy
* Support for multiple language models
* Document upload and processing capabilities
* Real-time query processing

Quick Start
----------
To get started quickly, follow these steps:

1. Install the required dependencies
2. Configure Ollama with your preferred models
3. Run the Streamlit application
4. Start querying your documents

For detailed instructions, please refer to the :doc:`installation` and :doc:`usage` sections.